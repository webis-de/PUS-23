{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"arno_experiments.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9kR1blw57Pyb+occK61jc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"n4eNz7RIrzow"},"source":["## Set globals"]},{"cell_type":"code","metadata":{"id":"PJwyfS7eiPWw","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1606468022368,"user_tz":-60,"elapsed":21066,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"ba88817e-31de-4512-a32a-e86c7403ee06"},"source":["# set paths\n","path_extractions = '/content/drive/My Drive/WIKING/extractions'\n","path_git = '/content/drive/My Drive/WIKING/WIKING_git'\n","path_my_tools = '/content/drive/My Drive/my_tools'\n","\n","# infiles\n","file_CRISPR_de = path_extractions + '/CRISPR_de' # get latest file version here: https://files.webis.de/wikipedia-tracing-innovations/\n","file_CRISPR_en = path_extractions + '/CRISPR_en' # get latest file version here: https://files.webis.de/wikipedia-tracing-innovations/\n","file_CRISPR_gene_editing_en = path_extractions + '/CRISPR_gene_editing_en' # get latest file version here: https://files.webis.de/wikipedia-tracing-innovations/ \n","file_events = path_git + '/data/CRISPR_events - events.csv'\n","file_accounts = path_git + '/data/CRISPR_events - accounts.csv'\n","\n","# outfiles\n","file_contexts_CRISPR_en = path_extractions + '/contexts_CRISPR_en.xlsx'\n","file_contexts_CRISPR_gene_editing_en = path_extractions + '/contexts_CRISPR_gene_editing_en.xlsx'\n","\n","# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# add git folder to path variable\n","import sys\n","sys.path.append(path_git + '/code')\n","\n","# import Wolfgang's classes:\n","from article.article import Article\n","\n","# import other modules\n","!pip install fuzzywuzzy # https://github.com/seatgeek/fuzzywuzzy\n","from fuzzywuzzy import fuzz\n","from fuzzywuzzy import process\n","import networkx as nx\n","!pip install python-louvain\n","from community import community_louvain\n","import re\n","import os\n","import json\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","import pprint\n","pp = pprint.PrettyPrinter(indent=4)\n","\n","# set working directory\n","os.chdir(path_git)\n","os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/WIKING/WIKING_git'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"BG3rjcwdsAvH"},"source":["## Functions"]},{"cell_type":"markdown","metadata":{"id":"6QRPtrvO9Mvp"},"source":["### Occurrence spans"]},{"cell_type":"code","metadata":{"id":"PrlDj91nsCLY"},"source":["def occurance_spans(keyphrase, article):\n","  ''' \n","  returns a list of time spans during which a keyphrase 'keyphrase' continously appears in an article 'a'\n","  '''\n","  gen = article.yield_revisions()\n","  last_rev_was_match = False\n","  spans = []\n","  for revision in gen:\n","    if keyphrase in revision.get_text():\n","    # if keyphrase in i.get_text().split('\\nLocus structure\\n')[0]: # Trick 17 to exclude everything after history section and practially only search in histroy section\n","      last_rev_that_matched = revision\n","      if not last_rev_was_match:\n","        span_beg = revision\n","        last_rev_was_match = True\n","    else:\n","      if last_rev_was_match:\n","        spans.append((span_beg, last_rev_that_matched))\n","        last_rev_was_match = False\n","  if last_rev_was_match:\n","    spans.append((span_beg, last_rev_that_matched))\n","  print(\n","      '\"{}\" was found in the following revisions of {}:\\n{}'.format(keyphrase, 'Test', '\\n'.join(['Span {}: {} - {}'.format(indx + 1, revision[0].timestamp, revision[1].timestamp) for indx,revision in enumerate(spans)])) \n","      if spans else '\"{}\" was not found in any revision of \"{}\"'.format(keyphrase, 'Test')\n","      )\n","  return spans"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y5HIHBrA9Sak"},"source":["### Unique contexts"]},{"cell_type":"code","metadata":{"id":"VA1WhsvGiqjB"},"source":["def find_all(s, sub): # https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring\n","  '''\n","  Helper function for unique_contexts\n","  '''\n","  start = 0\n","  while True:\n","    start = s.find(sub, start)\n","    if start == -1: return\n","    yield start\n","    start += len(sub) # use start += 1 to find overlapping matches"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eUn_KzFheAn"},"source":["def unique_contexts(keyphrase, article, width=50):\n","  ''' \n","  returns a pandas df with three columns:\n","  1) unique contexts of width in which keyphrase appears in article\n","  2) timestamp for first occurrence of each context\n","  3) url for first occurrence of each context\n","  '''\n","  kill = re.compile(r'\\s*\\[.*?\\]')\n","  gen = article.yield_revisions()\n","  unique_contexts = []\n","  timestamps = []\n","  urls = []\n","  for revision in gen:\n","    text = revision.get_text()\n","    # if s in text.split('\\nLocus structure\\n')[0]: # Trick 17 to exclude everything after history section and practially only search in histroy section\n","    if keyphrase in text:\n","      text = kill.sub('', text) # kill intext refs like '[23]'\n","      text = text.lower()\n","      for indx in find_all(text, keyphrase):\n","        # make '/n' the boundary for context\n","        before = text[indx - width : indx]\n","        after = text[indx + len(keyphrase): indx + len(keyphrase) + width]\n","        context = keyphrase[::-1]\n","        for char in before[::-1]:\n","          if char == '\\n':\n","            break\n","          context += char\n","        context = context[::-1]\n","        for char in after:\n","          if char == '\\n':\n","            break\n","          context += char\n","        # add unique contexts and add their meta data\n","        context = context.strip()\n","        if not context in unique_contexts:\n","          unique_contexts.append(context)\n","          timestamps.append(revision.timestamp.string)\n","          urls.append(revision.url)    \n","  print('Found {} unique contexts for \"{}\" in article \"{}\".'.format(len(unique_contexts), keyphrase, article.name))\n","  # return list(zip(unique_contexts, timestamps, urls))\n","  return pd.DataFrame({'Context':unique_contexts, \n","        'Timestamp':timestamps,\n","        'Url':urls}) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajWDEbMWHHSw"},"source":["### Left-right contexts"]},{"cell_type":"code","metadata":{"id":"7elYtyzQr-PP","executionInfo":{"status":"ok","timestamp":1606497456930,"user_tz":-60,"elapsed":640,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}}},"source":["def lr_context_graph(keyphrase, article, width=50):\n","  ''' \n","  Returns networkx DiGraph for links between contexts to the left and to the right of keyphrase\n","  '''\n","  gen = article.yield_revisions()\n","  DG = nx.DiGraph(keyphrase=keyphrase)\n","  for revision in gen:\n","    text = revision.get_text()\n","    text = text.lower()\n","    # text = re.sub(r'\\s*\\[.*?\\]','', text) # kill intext refs like '[23]'\n","    metadata = (revision.timestamp.string, revision.url)\n","    if keyphrase in text:\n","      for indx in find_all(text, keyphrase):\n","        # context left\n","        left = ''\n","        for char in text[indx - width : indx][::-1]:\n","          if char == '\\n': # make '/n' the boundary for context\n","            break\n","          left += char\n","        left = left[::-1].strip()\n","        # add/update node for context left\n","        if not left in DG:\n","          DG.add_node(left, as_left=[metadata], as_right=[])\n","        else:\n","          DG.nodes[left]['as_left'].append(metadata)\n","        # context right\n","        right = ''\n","        for char in text[indx + len(keyphrase): indx + len(keyphrase) + width]:\n","          if char == '\\n': # make '/n' the boundary for context\n","            break\n","          right += char\n","        right = right.strip()\n","        # add/update node for context right\n","        if not right in DG:\n","          DG.add_node(right, as_right=[metadata], as_left=[])\n","        else:\n","          DG.nodes[right]['as_right'].append(metadata)\n","        # add/update edge from context left to context right\n","        if not [left, right] in DG.edges:\n","          DG.add_edge(left, right, occurrences=[metadata])\n","        else:\n","            DG.edges[left,right]['occurrences'].append(metadata)\n","  return DG"],"execution_count":211,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o3QeZcjHpN83"},"source":["### Node communities"]},{"cell_type":"code","metadata":{"id":"4cJ9mGfolzDZ","executionInfo":{"status":"ok","timestamp":1606500736161,"user_tz":-60,"elapsed":619,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}}},"source":["def node_community_dic(DG, score_cutoff=90, scorer=fuzz.ratio):\n","  keyphrase = DG.graph['keyphrase']\n","  G = nx.Graph()\n","  for side in ['left', 'right']:\n","    choices = [node[0] for node in DG.nodes.data() if node[1]['as_{}'.format(side)]]\n","    length = len(choices)\n","    for query in choices:\n","      indx = choices.index(query) + 1\n","      if indx <= length:\n","        scores = process.extractBests(query, choices[choices.index(query) + 1:], score_cutoff=score_cutoff, limit=length, scorer=scorer) # https://github.com/seatgeek/fuzzywuzzy/blob/master/fuzzywuzzy/process.py\n","        edges = [(query, i[0]) for i in scores]\n","        G.add_edges_from(edges)\n","  return community_louvain.best_partition(G)"],"execution_count":253,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTaYKRvg6hN-"},"source":["### Master node for each community"]},{"cell_type":"code","metadata":{"id":"ATQugc1nqHFy","executionInfo":{"status":"ok","timestamp":1606500874131,"user_tz":-60,"elapsed":679,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}}},"source":["def master_nodes_dic(DG, ncd):\n","  '''\n","  Returns dictionary with community_ids as keys and nodes + latest occurrence as value\n","  '''\n","  result = {}\n","  reverse_mnd = {v:[k for k in mnd if mnd[k] == v] for v in mnd.values()}\n","  for community_id, nodes in reverse_mnd.items():\n","    candidates = []\n","    for node in nodes:\n","      latest = max([DG.nodes[node]['as_{}'.format(side)][-1][0] for side in ['left', 'right'] if DG.nodes[node]['as_{}'.format(side)]])\n","      candidates.append((node, latest))\n","    winner = sorted(candidates, key= lambda x: (x[1], x[0]), reverse=True)[0]\n","    result[community_id] = winner\n","  return result"],"execution_count":256,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KpfcElE48O3W"},"source":["### Reduced LR contexts graph (using ``lr_context_graph``, ``node_community_dic``, and ``master_nodes_dic``)"]},{"cell_type":"code","metadata":{"id":"wgGSr0Fl8ii7"},"source":["def reduce_lr_context_graph(DG, ncd, mnd):\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYzX8wKFrxkB"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"5pFtlIlNiYtw"},"source":["CRISPR_en = Article(file_CRISPR_en)\n","CRISPR_gene_editing_en = Article(file_CRISPR_gene_editing_en)\n","\n","# events = pd.read_csv(file_events)\n","# accounts = pd.read_csv(file_accounts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iN1eI6MICMu_"},"source":["## Experiments"]},{"cell_type":"markdown","metadata":{"id":"CPg3sesxo00n"},"source":["### Extract LR contexts and merge nodes "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAA1h3_wuO3D","executionInfo":{"status":"ok","timestamp":1606500810339,"user_tz":-60,"elapsed":615,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"6b665a2a-d41b-4e75-9d90-9da12af436f8"},"source":["DG = lr_context_graph('first', CRISPR_gene_editing_en, width=50)\n","ncd = node_community_dic(DG)\n","# sorted(ncd.items(), key=lambda item:(item[1], item[0]))\n","mnd = master_nodes_dic(DG, ncd)\n","mnd"],"execution_count":255,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: (\"340.2.[145] yang's white button mushroom was the\",\n","  '2020-11-02 10:35:49'),\n"," 1: ('t position 8 (help); no-break space character in |',\n","  '2020-01-31 21:33:44'),\n"," 2: ('demonstrated in 2012 in:[25][26]', '2019-02-18 01:48:30'),\n"," 3: ('organism genetically modified with the crispr-cas',\n","  '2020-11-02 10:35:49'),\n"," 4: ('= at position 5 (help); no-break space character i',\n","  '2020-01-31 21:33:44')}"]},"metadata":{"tags":[]},"execution_count":255}]},{"cell_type":"markdown","metadata":{"id":"IJppJpuY6ZAF"},"source":["### Older stuff"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_vRSWezNP31","executionInfo":{"status":"ok","timestamp":1606423116262,"user_tz":-60,"elapsed":76291,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"fe9f6fea-2e38-4840-ab2c-d17b6f5b9009"},"source":["contexts_first = unique_contexts('first', CRISPR_en, width=50)\n","contexts_first.to_excel(file_contexts_CRISPR_en)\n","\n","contexts_first = unique_contexts('first', CRISPR_gene_editing_en, width=50)\n","contexts_first.to_excel(file_contexts_CRISPR_gene_editing_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 143 unique contexts for \"first\" in article \"CRISPR_en\".\n","Found 23 unique contexts for \"first\" in article \"CRISPR_gene_editing_en\".\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJguDbiEIxKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606410107435,"user_tz":-60,"elapsed":85293,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"a30c97b9-40ce-41d7-9431-988943b84a8a"},"source":["timeline = occurance_spans('CRISPR Timeline', CRISPR_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"CRISPR Timeline\" was found in the following revisions of Test:\n","Span 1: {'datetime': datetime.datetime(2016, 9, 28, 9, 26, 29),\n"," 'day': 28,\n"," 'hour': 9,\n"," 'minute': 26,\n"," 'month': 9,\n"," 'second': 29,\n"," 'string': '2016-09-28 09:26:29',\n"," 'year': 2016} - {'datetime': datetime.datetime(2016, 12, 28, 8, 5, 49),\n"," 'day': 28,\n"," 'hour': 8,\n"," 'minute': 5,\n"," 'month': 12,\n"," 'second': 49,\n"," 'string': '2016-12-28 08:05:49',\n"," 'year': 2016}\n","Span 2: {'datetime': datetime.datetime(2019, 3, 18, 14, 33, 42),\n"," 'day': 18,\n"," 'hour': 14,\n"," 'minute': 33,\n"," 'month': 3,\n"," 'second': 42,\n"," 'string': '2019-03-18 14:33:42',\n"," 'year': 2019} - {'datetime': datetime.datetime(2019, 3, 18, 14, 34, 29),\n"," 'day': 18,\n"," 'hour': 14,\n"," 'minute': 34,\n"," 'month': 3,\n"," 'second': 29,\n"," 'string': '2019-03-18 14:34:29',\n"," 'year': 2019}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MtcXB1nBIkkq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604323635576,"user_tz":-60,"elapsed":74224,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"5367bc1b-4e68-442c-e636-2702ceb5a7c9"},"source":["# history_trick17 = occurance_spans('\\nLocus structure\\n', CRISPR_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"\n","Locus structure\n","\" was not found in any revision of \"Test\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R2nt3LFoDezQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604322549498,"user_tz":-60,"elapsed":78372,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"439e1385-bad6-41a0-e927-2043fe561133"},"source":["history = occurance_spans('\\nLocus structure\\n', CRISPR_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"\n","Locus structure\n","\" was found in the following revisions of Test:\n","Span 1: {'datetime': datetime.datetime(2013, 11, 24, 21, 3, 53),\n"," 'day': 24,\n"," 'hour': 21,\n"," 'minute': 3,\n"," 'month': 11,\n"," 'second': 53,\n"," 'string': '2013-11-24 21:03:53',\n"," 'year': 2013} - {'datetime': datetime.datetime(2016, 9, 22, 22, 1, 43),\n"," 'day': 22,\n"," 'hour': 22,\n"," 'minute': 1,\n"," 'month': 9,\n"," 'second': 43,\n"," 'string': '2016-09-22 22:01:43',\n"," 'year': 2016}\n","Span 2: {'datetime': datetime.datetime(2016, 9, 23, 0, 51, 24),\n"," 'day': 23,\n"," 'hour': 0,\n"," 'minute': 51,\n"," 'month': 9,\n"," 'second': 24,\n"," 'string': '2016-09-23 00:51:24',\n"," 'year': 2016} - {'datetime': datetime.datetime(2017, 9, 18, 8, 58, 26),\n"," 'day': 18,\n"," 'hour': 8,\n"," 'minute': 58,\n"," 'month': 9,\n"," 'second': 26,\n"," 'string': '2017-09-18 08:58:26',\n"," 'year': 2017}\n","Span 3: {'datetime': datetime.datetime(2017, 9, 18, 9, 0, 40),\n"," 'day': 18,\n"," 'hour': 9,\n"," 'minute': 0,\n"," 'month': 9,\n"," 'second': 40,\n"," 'string': '2017-09-18 09:00:40',\n"," 'year': 2017} - {'datetime': datetime.datetime(2018, 9, 24, 16, 48, 11),\n"," 'day': 24,\n"," 'hour': 16,\n"," 'minute': 48,\n"," 'month': 9,\n"," 'second': 11,\n"," 'string': '2018-09-24 16:48:11',\n"," 'year': 2018}\n","Span 4: {'datetime': datetime.datetime(2018, 9, 29, 6, 55, 25),\n"," 'day': 29,\n"," 'hour': 6,\n"," 'minute': 55,\n"," 'month': 9,\n"," 'second': 25,\n"," 'string': '2018-09-29 06:55:25',\n"," 'year': 2018} - {'datetime': datetime.datetime(2018, 9, 29, 6, 55, 25),\n"," 'day': 29,\n"," 'hour': 6,\n"," 'minute': 55,\n"," 'month': 9,\n"," 'second': 25,\n"," 'string': '2018-09-29 06:55:25',\n"," 'year': 2018}\n","Span 5: {'datetime': datetime.datetime(2018, 9, 30, 12, 48, 13),\n"," 'day': 30,\n"," 'hour': 12,\n"," 'minute': 48,\n"," 'month': 9,\n"," 'second': 13,\n"," 'string': '2018-09-30 12:48:13',\n"," 'year': 2018} - {'datetime': datetime.datetime(2019, 2, 28, 15, 35, 54),\n"," 'day': 28,\n"," 'hour': 15,\n"," 'minute': 35,\n"," 'month': 2,\n"," 'second': 54,\n"," 'string': '2019-02-28 15:35:54',\n"," 'year': 2019}\n","Span 6: {'datetime': datetime.datetime(2019, 2, 28, 15, 38, 47),\n"," 'day': 28,\n"," 'hour': 15,\n"," 'minute': 38,\n"," 'month': 2,\n"," 'second': 47,\n"," 'string': '2019-02-28 15:38:47',\n"," 'year': 2019} - {'datetime': datetime.datetime(2019, 5, 20, 16, 37, 18),\n"," 'day': 20,\n"," 'hour': 16,\n"," 'minute': 37,\n"," 'month': 5,\n"," 'second': 18,\n"," 'string': '2019-05-20 16:37:18',\n"," 'year': 2019}\n","Span 7: {'datetime': datetime.datetime(2019, 5, 21, 17, 37, 36),\n"," 'day': 21,\n"," 'hour': 17,\n"," 'minute': 37,\n"," 'month': 5,\n"," 'second': 36,\n"," 'string': '2019-05-21 17:37:36',\n"," 'year': 2019} - {'datetime': datetime.datetime(2020, 10, 7, 14, 20, 24),\n"," 'day': 7,\n"," 'hour': 14,\n"," 'minute': 20,\n"," 'month': 10,\n"," 'second': 24,\n"," 'string': '2020-10-07 14:20:24',\n"," 'year': 2020}\n","Span 8: {'datetime': datetime.datetime(2020, 10, 8, 1, 22, 24),\n"," 'day': 8,\n"," 'hour': 1,\n"," 'minute': 22,\n"," 'month': 10,\n"," 'second': 24,\n"," 'string': '2020-10-08 01:22:24',\n"," 'year': 2020} - {'datetime': datetime.datetime(2020, 10, 10, 21, 4, 18),\n"," 'day': 10,\n"," 'hour': 21,\n"," 'minute': 4,\n"," 'month': 10,\n"," 'second': 18,\n"," 'string': '2020-10-10 21:04:18',\n"," 'year': 2020}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPiKH4pzvbRs","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1603732761615,"user_tz":-60,"elapsed":937,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"5bed8eb7-3188-4821-db88-9ab8092531c6"},"source":["mojica = occurance_spans('Mojica', CRISPR_en)\n","# for span in doudna:\n","#   print(span[0].timestamp, span[1].timestamp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"Mojica\" was found in the following revisions of Test:\n","Span 1: 2010-01-11T02:11:54Z - 2020-09-02T08:32:27Z\n"],"name":"stdout"}]}]}