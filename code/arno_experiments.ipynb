{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"arno_experiments.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN3Cv0r2peBDLBBMwQxBDPx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"n4eNz7RIrzow"},"source":["## Set globals"]},{"cell_type":"code","metadata":{"id":"PJwyfS7eiPWw","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"ok","timestamp":1610459914964,"user_tz":-60,"elapsed":38908,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"a81e68dc-6860-4cbf-d164-630747ae0097"},"source":["# set paths\n","path_extractions = '/content/drive/My Drive/WIKING/extractions'\n","path_git = '/content/drive/My Drive/WIKING/WIKING_git'\n","path_my_tools = '/content/drive/My Drive/my_tools'\n","\n","# infiles\n","file_CRISPR_de = path_extractions + '/CRISPR_de' # get latest file version here: https://files.webis.de/wikipedia-tracing-innovations/\n","file_CRISPR_en = path_extractions + '/CRISPR_en' # get latest file version here: https://files.webis.de/wikipedia-tracing-innovations/\n","file_CRISPR_gene_editing_en = path_extractions + '/CRISPR_gene_editing_en' # get latest file version here: https://files.webis.de/wikipedia-tracing-innovations/ \n","file_events = path_git + '/data/CRISPR_events - events.csv'\n","file_accounts = path_git + '/data/CRISPR_events - accounts.csv'\n","\n","# outfiles\n","file_contexts_CRISPR_en = path_extractions + '/contexts_CRISPR_en.xlsx'\n","file_contexts_CRISPR_gene_editing_en = path_extractions + '/contexts_CRISPR_gene_editing_en.xlsx'\n","\n","# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# add git folder to path variable\n","import sys\n","sys.path.append(path_git + '/code')\n","\n","# import Wolfgang's classes:\n","from article.article import Article\n","\n","# import other modules\n","!pip install fuzzywuzzy # https://github.com/seatgeek/fuzzywuzzy\n","from fuzzywuzzy import fuzz\n","from fuzzywuzzy import process\n","import networkx as nx\n","!pip install python-louvain\n","from community import community_louvain\n","import re\n","import os\n","import json\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","import pprint\n","pp = pprint.PrettyPrinter(indent=4)\n","\n","# set working directory\n","os.chdir(path_git)\n","os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting fuzzywuzzy\n","  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"],"name":"stderr"},{"output_type":"stream","text":["Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (0.15)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from python-louvain) (1.19.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from python-louvain) (2.5)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->python-louvain) (4.4.2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/WIKING/WIKING_git'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"BG3rjcwdsAvH"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"VA1WhsvGiqjB"},"source":["def find_all(text, keyphrase): # https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring\n","  ''' Returns indices for all matches of keyphrase '''\n","  start = 0\n","  while True:\n","    start = text.find(keyphrase, start)\n","    if start == -1: \n","      return\n","    yield start\n","    start += len(keyphrase) # use start += 1 to find overlapping matches"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLjQwf0rnLmi","executionInfo":{"status":"ok","timestamp":1610480084064,"user_tz":-60,"elapsed":729,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}}},"source":["def keyphrase_in_context(keyphrase, article, width=50, score_cutoff=75, scorer=fuzz.ratio):\n","  ''' \n","  Returns df for contexts to the left and to the right of keyphrase\n","  '''\n","  gen = article.yield_revisions()\n","  contexts = []\n","  for revision in gen:\n","    text = revision.get_text()\n","    text = text.lower()\n","    if keyphrase in text:\n","      for indx in find_all(text, keyphrase):\n","        # context left\n","        left = ''\n","        for char in text[indx - width : indx][::-1]:\n","          if char == '\\n': # make '\\n' the boundary for context\n","            break\n","          left += char\n","        left = left[::-1].strip()\n","        # context right\n","        right = ''\n","        for char in text[indx + len(keyphrase): indx + len(keyphrase) + width]:\n","          if char == '\\n': # make '\\n' the boundary for context\n","            break\n","          right += char\n","        right = right.strip()\n","        contexts.append((revision.index, revision.timestamp.string, 0, left, keyphrase, right, 0, revision.revid, revision.url, revision.user, revision.userid, revision.comment,))\n","  df = pd.DataFrame(contexts, columns=['revindx','timestamp','left_id','left','keyphrase','right','right_id','revid','url','user','userid','comment',])\n","  \n","  # determine communities of similarity for left and right contexts\n","  for side in ['left', 'right']:\n","    G = nx.Graph()\n","    unique_contexts = list(df[side].unique())\n","    length = len(unique_contexts)\n","    for query in unique_contexts:\n","      indx = unique_contexts.index(query) + 1\n","      if indx <= length:\n","        scores = process.extractBests(query, unique_contexts[unique_contexts.index(query) + 1:], score_cutoff=score_cutoff, limit=length, scorer=scorer) # https://github.com/seatgeek/fuzzywuzzy/blob/master/fuzzywuzzy/process.py\n","        edges = [(query, i[0]) for i in scores]\n","        G.add_edges_from(edges)\n","    # add community_ids for lonesome contexts as well\n","    unique_contexts = set(unique_contexts)\n","    community_dic = community_louvain.best_partition(G)\n","    if community_dic:\n","      community_contexts = set(community_dic.keys())\n","      lonesome_contexts = unique_contexts - community_contexts\n","      lonesome_dic = {k:v for v,k in enumerate(lonesome_contexts,start=max(community_dic.values())+1)}\n","      community_dic.update(lonesome_dic) # hiermit nun 'lid' und 'rid' Spalten befüllen...\n","    else:\n","      community_dic = {k:v for v,k in enumerate(unique_contexts)}\n","    # add community_ids to df\n","    column = df.apply(lambda row: community_dic[row[side]], axis=1)\n","    df['{}_id'.format(side)] = column\n","  return df\n","  # # add community_ids for lonesome contexts as well\n","  # unique_contexts = set(unique_contexts['left'] + unique_contexts['right'])\n","  # community_dic = community_louvain.best_partition(G)\n","  # community_contexts = set(community_dic.keys())\n","  # lonesome_contexts = unique_contexts - community_contexts\n","  # lonesome_dic = {k:v for v,k in enumerate(lonesome_contexts,start=max(community_dic.values())+1)}\n","  # community_dic.update(lonesome_dic) # hiermit nun 'lid' und 'rid' Spalten befüllen...\n","  # # add community_ids for all left and right contexts in df\n","  # for side in ['left', 'right']:\n","  #   column = df.apply(lambda row: community_dic[row[side]], axis=1)\n","  #   df['{}_id'.format(side)] = column\n","  # return df"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aodKMqgBxmb8"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"gD4IDC16epDS"},"source":["CRISPR_en = Article(file_CRISPR_en)\n","CRISPR_gene_editing_en = Article(file_CRISPR_gene_editing_en)\n","# events = pd.read_csv(file_events)\n","# accounts = pd.read_csv(file_accounts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGgAMOM6zulH"},"source":["## Extract contexts"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghiJjtnuvUIB","executionInfo":{"status":"ok","timestamp":1610480125415,"user_tz":-60,"elapsed":9795,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"39727f34-6ff4-4206-9fba-af9060333737"},"source":["for article, article_name in [\n","                (CRISPR_en, 'CRISPR_en'),\n","                (CRISPR_gene_editing_en, 'CRISPR_gene_editing_en'),\n","                ]:\n","  print(article_name)\n","  for keyphrase in [\n","                    \n","                # terms\n","                'first',\n","                'discover',\n","                'patent',\n","                'nobel',\n","                'award',\n","                'prize',\n","\n","                # people:\n","                'doudna', \n","                'charpentier', \n","                'zhang', \n","                'šikšnys', # with all accents\n","                  'šiksnys', # only first accent\n","                  'sikšnys', # only second accent\n","                  'siksnys', # no accents\n","                'gašiūnas', # with all accents\n","                  'gasiūnas', # only first accent\n","                  'gašiunas', # only second accent\n","                  'gasiunas', # no accents\n","                'horvath', # auch im Zusammenhang mit Šikšnys, aber auch so interessant\n","                'barrangou', # auch im Zusammenhang mit Šikšnys, aber auch so interessant\n","                'church',\n","                'brouns',\n","                'mojica',\n","                'ishino',\n","                'jansen',\n","                'marraffini',\n","                'sontheimer',\n","                'koonin',\n","                'moineau',\n","                'bolotin',\n","                'sorokin',\n","                'makarova',\n","                'pourcel',\n","                'overbeek',\n","                'liang',\n","                ' xu', # added space!\n","                'lander', # review\n","                \n","                # institutions:\n","                'osaka',\n","                'alicante',\n","                'danisco',\n","                'broad',\n","                'harvard',\n","                'university of california', \n","                'berkeley',\n","                \n","                ]:\n","    print('\\t' + keyphrase)\n","    df = keyphrase_in_context(keyphrase, article, width=100, score_cutoff=75)\n","    df.sort_values(by=['left_id','timestamp'])\n","    df.to_excel(path_extractions + '/contexts_{}_{}.xlsx'.format(article_name, keyphrase))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["CRISPR_gene_editing_en\n","\tfirst\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4k2Me_0RyhFO"},"source":["### CRISPR_en: \"first\"\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":788},"id":"CPm0Mh-syhFP","executionInfo":{"status":"ok","timestamp":1606682187152,"user_tz":-60,"elapsed":97739,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"4885e2f4-70b3-4a97-da4a-cf6c8843f258"},"source":["df = keyphrase_in_context('first', CRISPR_en, width=50, score_cutoff=75)\n","df.to_excel(file_contexts_CRISPR_en)\n","df.sort_values(by=['left_id','timestamp'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>revindx</th>\n","      <th>timestamp</th>\n","      <th>left_id</th>\n","      <th>left</th>\n","      <th>keyphrase</th>\n","      <th>right</th>\n","      <th>right_id</th>\n","      <th>revid</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25</th>\n","      <td>133</td>\n","      <td>2012-01-07 04:36:56</td>\n","      <td>0</td>\n","      <td>n of the crispr-cas system in 2012[21] provided a</td>\n","      <td>first</td>\n","      <td>step toward realization of some of the several pr</td>\n","      <td>33</td>\n","      <td>470025144</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>134</td>\n","      <td>2012-08-01 19:27:33</td>\n","      <td>0</td>\n","      <td>n of the crispr-cas system in 2012[21] provided a</td>\n","      <td>first</td>\n","      <td>step toward realization of some of the several pr</td>\n","      <td>33</td>\n","      <td>505309163</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>135</td>\n","      <td>2012-08-22 21:44:35</td>\n","      <td>0</td>\n","      <td>n of the crispr-cas system in 2012[21] provided a</td>\n","      <td>first</td>\n","      <td>step toward realization of some of the several pr</td>\n","      <td>33</td>\n","      <td>508685743</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>136</td>\n","      <td>2012-12-06 19:12:03</td>\n","      <td>0</td>\n","      <td>n of the crispr-cas system in 2012[21] provided a</td>\n","      <td>first</td>\n","      <td>step toward realization of some of the several pr</td>\n","      <td>33</td>\n","      <td>526751001</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>137</td>\n","      <td>2012-12-11 08:13:19</td>\n","      <td>0</td>\n","      <td>n of the crispr-cas system in 2012[21] provided a</td>\n","      <td>first</td>\n","      <td>step toward realization of some of the several pr</td>\n","      <td>33</td>\n","      <td>527490124</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>26284</th>\n","      <td>2039</td>\n","      <td>2020-11-02 21:24:41</td>\n","      <td>75</td>\n","      <td>th the newly acquired spacer inserted between the</td>\n","      <td>first</td>\n","      <td>and second direct repeats.[95][116]</td>\n","      <td>5</td>\n","      <td>986762186</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>26297</th>\n","      <td>2040</td>\n","      <td>2020-11-03 09:53:58</td>\n","      <td>75</td>\n","      <td>th the newly acquired spacer inserted between the</td>\n","      <td>first</td>\n","      <td>and second direct repeats.[95][116]</td>\n","      <td>5</td>\n","      <td>986842914</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>26310</th>\n","      <td>2041</td>\n","      <td>2020-11-03 20:16:34</td>\n","      <td>75</td>\n","      <td>th the newly acquired spacer inserted between the</td>\n","      <td>first</td>\n","      <td>and second direct repeats.[95][116]</td>\n","      <td>5</td>\n","      <td>986927023</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>26323</th>\n","      <td>2042</td>\n","      <td>2020-11-03 22:56:29</td>\n","      <td>75</td>\n","      <td>th the newly acquired spacer inserted between the</td>\n","      <td>first</td>\n","      <td>and second direct repeats.[95][116]</td>\n","      <td>5</td>\n","      <td>986949106</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>26336</th>\n","      <td>2043</td>\n","      <td>2020-11-04 21:00:44</td>\n","      <td>75</td>\n","      <td>th the newly acquired spacer inserted between the</td>\n","      <td>first</td>\n","      <td>and second direct repeats.[95][116]</td>\n","      <td>5</td>\n","      <td>987088136</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>26340 rows × 9 columns</p>\n","</div>"],"text/plain":["       revindx  ...                                                url\n","25         133  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","27         134  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","29         135  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","31         136  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","33         137  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","...        ...  ...                                                ...\n","26284     2039  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","26297     2040  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","26310     2041  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","26323     2042  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","26336     2043  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","\n","[26340 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"fc1dPCidx823"},"source":["### CRISPR_gene_editing_en: \"first\"\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":771},"id":"dB8a9egkrWyg","executionInfo":{"status":"ok","timestamp":1606681779613,"user_tz":-60,"elapsed":6031,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"508e83c7-d9e5-4ccc-8689-f495287716c9"},"source":["df = keyphrase_in_context('first', CRISPR_gene_editing_en, width=50, score_cutoff=75)\n","df.to_excel(file_contexts_CRISPR_gene_editing_en)\n","df.sort_values(by=['left_id','timestamp'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>revindx</th>\n","      <th>timestamp</th>\n","      <th>left_id</th>\n","      <th>left</th>\n","      <th>keyphrase</th>\n","      <th>right</th>\n","      <th>right_id</th>\n","      <th>revid</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2019-02-17 06:32:48</td>\n","      <td>0</td>\n","      <td>340.2.[131] yang's white button mushroom was the</td>\n","      <td>first</td>\n","      <td>organism genetically modified with the crispr/cas</td>\n","      <td>3</td>\n","      <td>883727671</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>2019-02-17 06:33:54</td>\n","      <td>0</td>\n","      <td>340.2.[131] yang's white button mushroom was the</td>\n","      <td>first</td>\n","      <td>organism genetically modified with the crispr/cas</td>\n","      <td>3</td>\n","      <td>883727741</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>2</td>\n","      <td>2019-02-17 06:35:41</td>\n","      <td>0</td>\n","      <td>340.2.[131] yang's white button mushroom was the</td>\n","      <td>first</td>\n","      <td>organism genetically modified with the crispr/cas</td>\n","      <td>3</td>\n","      <td>883727860</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>3</td>\n","      <td>2019-02-17 06:37:14</td>\n","      <td>0</td>\n","      <td>340.2.[132] yang's white button mushroom was the</td>\n","      <td>first</td>\n","      <td>organism genetically modified with the crispr/cas</td>\n","      <td>3</td>\n","      <td>883727959</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>4</td>\n","      <td>2019-02-17 06:39:37</td>\n","      <td>0</td>\n","      <td>340.2.[131] yang's white button mushroom was the</td>\n","      <td>first</td>\n","      <td>organism genetically modified with the crispr/cas</td>\n","      <td>3</td>\n","      <td>883728113</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1447</th>\n","      <td>184</td>\n","      <td>2020-10-23 09:36:41</td>\n","      <td>13</td>\n","      <td>ay:table-row}.mw-parser-output .portal&gt;ul&gt;li&gt;s...</td>\n","      <td>first</td>\n","      <td>-child{display:table-cell;padding:0.2em;vertic...</td>\n","      <td>15</td>\n","      <td>984993980</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>1458</th>\n","      <td>185</td>\n","      <td>2020-11-02 04:29:36</td>\n","      <td>13</td>\n","      <td>ay:table-row}.mw-parser-output .portal&gt;ul&gt;li&gt;s...</td>\n","      <td>first</td>\n","      <td>-child{display:table-cell;padding:0.2em;vertic...</td>\n","      <td>15</td>\n","      <td>986649176</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>1469</th>\n","      <td>186</td>\n","      <td>2020-11-02 10:34:00</td>\n","      <td>13</td>\n","      <td>ay:table-row}.mw-parser-output .portal&gt;ul&gt;li&gt;s...</td>\n","      <td>first</td>\n","      <td>-child{display:table-cell;padding:0.2em;vertic...</td>\n","      <td>15</td>\n","      <td>986682078</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>1480</th>\n","      <td>187</td>\n","      <td>2020-11-02 10:35:18</td>\n","      <td>13</td>\n","      <td>ay:table-row}.mw-parser-output .portal&gt;ul&gt;li&gt;s...</td>\n","      <td>first</td>\n","      <td>-child{display:table-cell;padding:0.2em;vertic...</td>\n","      <td>15</td>\n","      <td>986682164</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","    <tr>\n","      <th>1491</th>\n","      <td>188</td>\n","      <td>2020-11-02 10:35:49</td>\n","      <td>13</td>\n","      <td>ay:table-row}.mw-parser-output .portal&gt;ul&gt;li&gt;s...</td>\n","      <td>first</td>\n","      <td>-child{display:table-cell;padding:0.2em;vertic...</td>\n","      <td>15</td>\n","      <td>986682206</td>\n","      <td>https://en.wikipedia.org/w/index.php?title=CRI...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1497 rows × 9 columns</p>\n","</div>"],"text/plain":["      revindx  ...                                                url\n","3           0  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","10          1  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","17          2  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","24          3  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","31          4  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","...       ...  ...                                                ...\n","1447      184  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","1458      185  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","1469      186  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","1480      187  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","1491      188  ...  https://en.wikipedia.org/w/index.php?title=CRI...\n","\n","[1497 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"PgVJr7mPzwj_"},"source":["# Old stuff..."]},{"cell_type":"markdown","metadata":{"id":"6QRPtrvO9Mvp"},"source":["### Occurrence spans"]},{"cell_type":"code","metadata":{"id":"PrlDj91nsCLY"},"source":["def occurance_spans(keyphrase, article):\n","  ''' \n","  returns a list of time spans during which a keyphrase 'keyphrase' continously appears in an article 'a'\n","  '''\n","  gen = article.yield_revisions()\n","  last_rev_was_match = False\n","  spans = []\n","  for revision in gen:\n","    if keyphrase in revision.get_text():\n","    # if keyphrase in i.get_text().split('\\nLocus structure\\n')[0]: # Trick 17 to exclude everything after history section and practially only search in histroy section\n","      last_rev_that_matched = revision\n","      if not last_rev_was_match:\n","        span_beg = revision\n","        last_rev_was_match = True\n","    else:\n","      if last_rev_was_match:\n","        spans.append((span_beg, last_rev_that_matched))\n","        last_rev_was_match = False\n","  if last_rev_was_match:\n","    spans.append((span_beg, last_rev_that_matched))\n","  print(\n","      '\"{}\" was found in the following revisions of {}:\\n{}'.format(keyphrase, 'Test', '\\n'.join(['Span {}: {} - {}'.format(indx + 1, revision[0].timestamp, revision[1].timestamp) for indx,revision in enumerate(spans)])) \n","      if spans else '\"{}\" was not found in any revision of \"{}\"'.format(keyphrase, 'Test')\n","      )\n","  return spans"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y5HIHBrA9Sak"},"source":["### Unique contexts"]},{"cell_type":"code","metadata":{"id":"_eUn_KzFheAn"},"source":["def unique_contexts(keyphrase, article, width=50):\n","  ''' \n","  returns a pandas df with three columns:\n","  1) unique contexts of width in which keyphrase appears in article\n","  2) timestamp for first occurrence of each context\n","  3) url for first occurrence of each context\n","  '''\n","  kill = re.compile(r'\\s*\\[.*?\\]')\n","  gen = article.yield_revisions()\n","  unique_contexts = []\n","  timestamps = []\n","  urls = []\n","  for revision in gen:\n","    text = revision.get_text()\n","    # if s in text.split('\\nLocus structure\\n')[0]: # Trick 17 to exclude everything after history section and practially only search in histroy section\n","    if keyphrase in text:\n","      text = kill.sub('', text) # kill intext refs like '[23]'\n","      text = text.lower()\n","      for indx in find_all(text, keyphrase):\n","        # make '/n' the boundary for context\n","        before = text[indx - width : indx]\n","        after = text[indx + len(keyphrase): indx + len(keyphrase) + width]\n","        context = keyphrase[::-1]\n","        for char in before[::-1]:\n","          if char == '\\n':\n","            break\n","          context += char\n","        context = context[::-1]\n","        for char in after:\n","          if char == '\\n':\n","            break\n","          context += char\n","        # add unique contexts and add their meta data\n","        context = context.strip()\n","        if not context in unique_contexts:\n","          unique_contexts.append(context)\n","          timestamps.append(revision.timestamp.string)\n","          urls.append(revision.url)    \n","  print('Found {} unique contexts for \"{}\" in article \"{}\".'.format(len(unique_contexts), keyphrase, article.name))\n","  # return list(zip(unique_contexts, timestamps, urls))\n","  return pd.DataFrame({'Context':unique_contexts, \n","        'Timestamp':timestamps,\n","        'Url':urls}) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajWDEbMWHHSw"},"source":["### Left-right contexts"]},{"cell_type":"code","metadata":{"id":"7elYtyzQr-PP"},"source":["def lr_context_graph(keyphrase, article, width=50):\n","  ''' \n","  Returns networkx DiGraph for links between contexts to the left and to the right of keyphrase\n","  '''\n","  gen = article.yield_revisions()\n","  DG = nx.DiGraph(keyphrase=keyphrase)\n","  for revision in gen:\n","    text = revision.get_text()\n","    text = text.lower()\n","    # text = re.sub(r'\\s*\\[.*?\\]','', text) # kill intext refs like '[23]'\n","    metadata = (revision.timestamp.string, revision.url)\n","    if keyphrase in text:\n","      for indx in find_all(text, keyphrase):\n","        # context left\n","        left = ''\n","        for char in text[indx - width : indx][::-1]:\n","          if char == '\\n': # make '/n' the boundary for context\n","            break\n","          left += char\n","        left = left[::-1].strip()\n","        # add/update node for context left\n","        if not left in DG:\n","          DG.add_node(left, as_left=[metadata], as_right=[])\n","        else:\n","          DG.nodes[left]['as_left'].append(metadata)\n","        # context right\n","        right = ''\n","        for char in text[indx + len(keyphrase): indx + len(keyphrase) + width]:\n","          if char == '\\n': # make '/n' the boundary for context\n","            break\n","          right += char\n","        right = right.strip()\n","        # add/update node for context right\n","        if not right in DG:\n","          DG.add_node(right, as_right=[metadata], as_left=[])\n","        else:\n","          DG.nodes[right]['as_right'].append(metadata)\n","        # add/update edge from context left to context right\n","        if not [left, right] in DG.edges:\n","          DG.add_edge(left, right, occurrences=[metadata])\n","        else:\n","            DG.edges[left,right]['occurrences'].append(metadata)\n","  return DG"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o3QeZcjHpN83"},"source":["### Node communities"]},{"cell_type":"code","metadata":{"id":"4cJ9mGfolzDZ"},"source":["def node_community_dic(DG, score_cutoff=90, scorer=fuzz.ratio):\n","  keyphrase = DG.graph['keyphrase']\n","  G = nx.Graph()\n","  for side in ['left', 'right']:\n","    choices = [node[0] for node in DG.nodes.data() if node[1]['as_{}'.format(side)]]\n","    length = len(choices)\n","    for query in choices:\n","      indx = choices.index(query) + 1\n","      if indx <= length:\n","        scores = process.extractBests(query, choices[choices.index(query) + 1:], score_cutoff=score_cutoff, limit=length, scorer=scorer) # https://github.com/seatgeek/fuzzywuzzy/blob/master/fuzzywuzzy/process.py\n","        edges = [(query, i[0]) for i in scores]\n","        G.add_edges_from(edges)\n","  return community_louvain.best_partition(G)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTaYKRvg6hN-"},"source":["### Master node for each community"]},{"cell_type":"code","metadata":{"id":"ATQugc1nqHFy"},"source":["def master_nodes_dic(DG, ncd):\n","  '''\n","  Returns dictionary with community_ids as keys and nodes + latest occurrence as value\n","  '''\n","  result = {}\n","  reverse_mnd = {v:[k for k in mnd if mnd[k] == v] for v in mnd.values()}\n","  for community_id, nodes in reverse_mnd.items():\n","    candidates = []\n","    for node in nodes:\n","      latest = max([DG.nodes[node]['as_{}'.format(side)][-1][0] for side in ['left', 'right'] if DG.nodes[node]['as_{}'.format(side)]])\n","      candidates.append((node, latest))\n","    winner = sorted(candidates, key= lambda x: (x[1], x[0]), reverse=True)[0]\n","    result[community_id] = winner\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KpfcElE48O3W"},"source":["### Reduced LR contexts graph (using ``lr_context_graph``, ``node_community_dic``, and ``master_nodes_dic``)"]},{"cell_type":"code","metadata":{"id":"wgGSr0Fl8ii7"},"source":["def reduce_lr_context_graph(DG, ncd, mnd):\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYzX8wKFrxkB"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"5pFtlIlNiYtw"},"source":["CRISPR_en = Article(file_CRISPR_en)\n","CRISPR_gene_editing_en = Article(file_CRISPR_gene_editing_en)\n","\n","# events = pd.read_csv(file_events)\n","# accounts = pd.read_csv(file_accounts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iN1eI6MICMu_"},"source":["## Experiments"]},{"cell_type":"markdown","metadata":{"id":"CPg3sesxo00n"},"source":["### Extract LR contexts and merge nodes "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZAA1h3_wuO3D","executionInfo":{"status":"ok","timestamp":1606500810339,"user_tz":-60,"elapsed":615,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"6b665a2a-d41b-4e75-9d90-9da12af436f8"},"source":["DG = lr_context_graph('first', CRISPR_gene_editing_en, width=50)\n","ncd = node_community_dic(DG)\n","# sorted(ncd.items(), key=lambda item:(item[1], item[0]))\n","mnd = master_nodes_dic(DG, ncd)\n","mnd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: (\"340.2.[145] yang's white button mushroom was the\",\n","  '2020-11-02 10:35:49'),\n"," 1: ('t position 8 (help); no-break space character in |',\n","  '2020-01-31 21:33:44'),\n"," 2: ('demonstrated in 2012 in:[25][26]', '2019-02-18 01:48:30'),\n"," 3: ('organism genetically modified with the crispr-cas',\n","  '2020-11-02 10:35:49'),\n"," 4: ('= at position 5 (help); no-break space character i',\n","  '2020-01-31 21:33:44')}"]},"metadata":{"tags":[]},"execution_count":255}]},{"cell_type":"markdown","metadata":{"id":"IJppJpuY6ZAF"},"source":["### Older stuff"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_vRSWezNP31","executionInfo":{"status":"ok","timestamp":1606423116262,"user_tz":-60,"elapsed":76291,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"fe9f6fea-2e38-4840-ab2c-d17b6f5b9009"},"source":["contexts_first = unique_contexts('first', CRISPR_en, width=50)\n","contexts_first.to_excel(file_contexts_CRISPR_en)\n","\n","contexts_first = unique_contexts('first', CRISPR_gene_editing_en, width=50)\n","contexts_first.to_excel(file_contexts_CRISPR_gene_editing_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 143 unique contexts for \"first\" in article \"CRISPR_en\".\n","Found 23 unique contexts for \"first\" in article \"CRISPR_gene_editing_en\".\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJguDbiEIxKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606410107435,"user_tz":-60,"elapsed":85293,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"a30c97b9-40ce-41d7-9431-988943b84a8a"},"source":["timeline = occurance_spans('CRISPR Timeline', CRISPR_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"CRISPR Timeline\" was found in the following revisions of Test:\n","Span 1: {'datetime': datetime.datetime(2016, 9, 28, 9, 26, 29),\n"," 'day': 28,\n"," 'hour': 9,\n"," 'minute': 26,\n"," 'month': 9,\n"," 'second': 29,\n"," 'string': '2016-09-28 09:26:29',\n"," 'year': 2016} - {'datetime': datetime.datetime(2016, 12, 28, 8, 5, 49),\n"," 'day': 28,\n"," 'hour': 8,\n"," 'minute': 5,\n"," 'month': 12,\n"," 'second': 49,\n"," 'string': '2016-12-28 08:05:49',\n"," 'year': 2016}\n","Span 2: {'datetime': datetime.datetime(2019, 3, 18, 14, 33, 42),\n"," 'day': 18,\n"," 'hour': 14,\n"," 'minute': 33,\n"," 'month': 3,\n"," 'second': 42,\n"," 'string': '2019-03-18 14:33:42',\n"," 'year': 2019} - {'datetime': datetime.datetime(2019, 3, 18, 14, 34, 29),\n"," 'day': 18,\n"," 'hour': 14,\n"," 'minute': 34,\n"," 'month': 3,\n"," 'second': 29,\n"," 'string': '2019-03-18 14:34:29',\n"," 'year': 2019}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MtcXB1nBIkkq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604323635576,"user_tz":-60,"elapsed":74224,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"5367bc1b-4e68-442c-e636-2702ceb5a7c9"},"source":["# history_trick17 = occurance_spans('\\nLocus structure\\n', CRISPR_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"\n","Locus structure\n","\" was not found in any revision of \"Test\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R2nt3LFoDezQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604322549498,"user_tz":-60,"elapsed":78372,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"439e1385-bad6-41a0-e927-2043fe561133"},"source":["history = occurance_spans('\\nLocus structure\\n', CRISPR_en)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"\n","Locus structure\n","\" was found in the following revisions of Test:\n","Span 1: {'datetime': datetime.datetime(2013, 11, 24, 21, 3, 53),\n"," 'day': 24,\n"," 'hour': 21,\n"," 'minute': 3,\n"," 'month': 11,\n"," 'second': 53,\n"," 'string': '2013-11-24 21:03:53',\n"," 'year': 2013} - {'datetime': datetime.datetime(2016, 9, 22, 22, 1, 43),\n"," 'day': 22,\n"," 'hour': 22,\n"," 'minute': 1,\n"," 'month': 9,\n"," 'second': 43,\n"," 'string': '2016-09-22 22:01:43',\n"," 'year': 2016}\n","Span 2: {'datetime': datetime.datetime(2016, 9, 23, 0, 51, 24),\n"," 'day': 23,\n"," 'hour': 0,\n"," 'minute': 51,\n"," 'month': 9,\n"," 'second': 24,\n"," 'string': '2016-09-23 00:51:24',\n"," 'year': 2016} - {'datetime': datetime.datetime(2017, 9, 18, 8, 58, 26),\n"," 'day': 18,\n"," 'hour': 8,\n"," 'minute': 58,\n"," 'month': 9,\n"," 'second': 26,\n"," 'string': '2017-09-18 08:58:26',\n"," 'year': 2017}\n","Span 3: {'datetime': datetime.datetime(2017, 9, 18, 9, 0, 40),\n"," 'day': 18,\n"," 'hour': 9,\n"," 'minute': 0,\n"," 'month': 9,\n"," 'second': 40,\n"," 'string': '2017-09-18 09:00:40',\n"," 'year': 2017} - {'datetime': datetime.datetime(2018, 9, 24, 16, 48, 11),\n"," 'day': 24,\n"," 'hour': 16,\n"," 'minute': 48,\n"," 'month': 9,\n"," 'second': 11,\n"," 'string': '2018-09-24 16:48:11',\n"," 'year': 2018}\n","Span 4: {'datetime': datetime.datetime(2018, 9, 29, 6, 55, 25),\n"," 'day': 29,\n"," 'hour': 6,\n"," 'minute': 55,\n"," 'month': 9,\n"," 'second': 25,\n"," 'string': '2018-09-29 06:55:25',\n"," 'year': 2018} - {'datetime': datetime.datetime(2018, 9, 29, 6, 55, 25),\n"," 'day': 29,\n"," 'hour': 6,\n"," 'minute': 55,\n"," 'month': 9,\n"," 'second': 25,\n"," 'string': '2018-09-29 06:55:25',\n"," 'year': 2018}\n","Span 5: {'datetime': datetime.datetime(2018, 9, 30, 12, 48, 13),\n"," 'day': 30,\n"," 'hour': 12,\n"," 'minute': 48,\n"," 'month': 9,\n"," 'second': 13,\n"," 'string': '2018-09-30 12:48:13',\n"," 'year': 2018} - {'datetime': datetime.datetime(2019, 2, 28, 15, 35, 54),\n"," 'day': 28,\n"," 'hour': 15,\n"," 'minute': 35,\n"," 'month': 2,\n"," 'second': 54,\n"," 'string': '2019-02-28 15:35:54',\n"," 'year': 2019}\n","Span 6: {'datetime': datetime.datetime(2019, 2, 28, 15, 38, 47),\n"," 'day': 28,\n"," 'hour': 15,\n"," 'minute': 38,\n"," 'month': 2,\n"," 'second': 47,\n"," 'string': '2019-02-28 15:38:47',\n"," 'year': 2019} - {'datetime': datetime.datetime(2019, 5, 20, 16, 37, 18),\n"," 'day': 20,\n"," 'hour': 16,\n"," 'minute': 37,\n"," 'month': 5,\n"," 'second': 18,\n"," 'string': '2019-05-20 16:37:18',\n"," 'year': 2019}\n","Span 7: {'datetime': datetime.datetime(2019, 5, 21, 17, 37, 36),\n"," 'day': 21,\n"," 'hour': 17,\n"," 'minute': 37,\n"," 'month': 5,\n"," 'second': 36,\n"," 'string': '2019-05-21 17:37:36',\n"," 'year': 2019} - {'datetime': datetime.datetime(2020, 10, 7, 14, 20, 24),\n"," 'day': 7,\n"," 'hour': 14,\n"," 'minute': 20,\n"," 'month': 10,\n"," 'second': 24,\n"," 'string': '2020-10-07 14:20:24',\n"," 'year': 2020}\n","Span 8: {'datetime': datetime.datetime(2020, 10, 8, 1, 22, 24),\n"," 'day': 8,\n"," 'hour': 1,\n"," 'minute': 22,\n"," 'month': 10,\n"," 'second': 24,\n"," 'string': '2020-10-08 01:22:24',\n"," 'year': 2020} - {'datetime': datetime.datetime(2020, 10, 10, 21, 4, 18),\n"," 'day': 10,\n"," 'hour': 21,\n"," 'minute': 4,\n"," 'month': 10,\n"," 'second': 18,\n"," 'string': '2020-10-10 21:04:18',\n"," 'year': 2020}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPiKH4pzvbRs","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1603732761615,"user_tz":-60,"elapsed":937,"user":{"displayName":"Arno Simons","photoUrl":"","userId":"02448447039943627700"}},"outputId":"5bed8eb7-3188-4821-db88-9ab8092531c6"},"source":["mojica = occurance_spans('Mojica', CRISPR_en)\n","# for span in doudna:\n","#   print(span[0].timestamp, span[1].timestamp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"Mojica\" was found in the following revisions of Test:\n","Span 1: 2010-01-11T02:11:54Z - 2020-09-02T08:32:27Z\n"],"name":"stdout"}]}]}